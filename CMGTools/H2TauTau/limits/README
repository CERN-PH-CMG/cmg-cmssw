
***Quick running instructions:
rm -f *.ps *.txt *.root *.log
source createDataCards.sh
source combineCards.sh
source computeLimits.sh 
root -b plotLimits.C\(0\)
root -b plotLimits.C\(1\)
root -b plotLimits.C\(2\)
root -b plotLimits.C\(3\)


***For up to date info see the Twiki
https://twiki.cern.ch/twiki/bin/viewauth/CMS/%20SWGuideHiggsAnalysisCombinedLimit)

***Installation instructions:

cd CMSSW_4_2_8/src 
cmsenv
cvs co  HiggsAnalysis/CombinedLimit
scramv1 b


***Notes macros:

-histosForLimit.C macro will create the datacard and the rootfile for on particular category and higgs mass.
-the "combine" command will compute the limit for one data card.
-the above shell scripts combine the cards and compute all the limits
-the plotLimits.C makes the plot as a function of mass

***data cards for different categories/channels are combined like this:
combineCards.py Name1=card1.txt Name2=card2.txt .... > card.txt 


***Notes on the types of limit computations
There are two ways to compute the limit:

1) The asymptotic CLs method that allows to compute quickly an estimate of the observed and expected limits

2) The CMS choice for official results that is the modified CLs (frequentistic) limit

How to run limits

					Asymptotic CLs method

command: combine -M Asymptotic --rMax 50 datacard.txt

Options rMax and rMin manually restrict the range of signal strengths to consider. A too small value of rMax will bias your limit towards low values, since you are restricting the integration range, while a too large value will bias you to higher limits. Choose a rMax that is 2-3 times the expected limit.

The program will print out the limit on the signal strength r (number of signal events/number of expected signal events) e.g. Observed Limit: r < 1.6297 @ 95% CL , the median expected limit, Expected 50.0%: r < 2.3111 and edges of the 68% and 95% ranges for the expected limits.

					Modified CLs (frequentistic) limit

If your model is complex, or you need to know the limit accurately, or you want expected limits, then running the computation in a single job might not be feasible.
The alternative approach is to compute a grid of distributions of the test statistics for various values of the signal strength, a task that is easy to parallelize, and then use that grid to compute the observed limit (and also the expected ones).

a) To create the grid: python makeGridUsingCrab.py datacard.txt min max -n point -o name
This will create a crab cfg file name.cfg and a script name.sh. You can then just create and submit the jobs from that cfg file and merge the output rootfiles with hadd. For example hadd muTau_mH115.root output*.root

b) To obtain expected limit: combine datacard.txt -M HybridNew --freq --testStat LHC --grid=muTau_mH115.root --expectedFromGrid 0.5
	-0.5 gives the median; use 0.16/0.84 to get the endpoints of 68% interval, 0.0275/0.975 to get the 95% one

c) To obtain observed limit: combine datacard.txt -M HybridNew --freq --testStat LHC --grid=muTau_mH115.root
 


